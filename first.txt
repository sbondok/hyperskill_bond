we're going to learn about the first

and one of the most important

software architecture building blocks,

which is used in pretty much 100%

of all real-life, large-scale systems.

This building block is called a load balancer.

After getting some motivation for using a load balancer,

we will learn what quality attributes

this building block can provide to our system.

And finally, we will learn about

the different types of load balancing solutions

and how to use those solutions

in architecting a real-life, large-scale system.

So let's start with an introduction to load balancers.

As the name suggests, the basic role of a load balancer

is to balance the traffic load

among a group of servers in our system.

If we remember from the previous lectures,

the best way to achieve high availability

and horizontal scalability

is running multiple identical instances of our application

on multiple computers.

However, without a load balancer,

the client application

that may run on our customer's computers

will have to know the addresses of those computers,

as well as the number of the application instances.

This tightly couples the client application

to our system's internal implementation

and makes it very hard for us to make any changes.

So while the main purpose of a load balancer

is to balance the load among a group of servers

to make sure that no individual server

is overloaded as an added feature,

most load balancing solutions also provide an abstraction

between the client application and our group of servers.

This abstraction makes our entire system

look like a single server,

capable of immense computing power and a lot of memory.

Now, different load balancing solutions

offer different levels of abstraction,

which we will see very soon

when we talk about different types of load balancers.

Now, let's talk about what specific quality attributes

a load balancer can provide to our system.

The first quality attribute we get from a load balancer

is high scalability.

As we already mentioned, by hiding a group of servers

behind a load balancer, we can scale our system horizontally

both up and down by adding additional servers

when the load on our system increases

and remove unnecessary servers

when the load on our system decreases to save money.

In a cloud environment

where we can easily rent more hardware on demand,

we can use auto-scaling policies

to intelligently add or remove servers

based on different criteria,

like the number of requests per second,

network bandwidth, and so on.

The next quality attribute

the load balancer provides us with is high availability.

Most load balancers can easily be configured

to stop sending traffic to servers that cannot be reached.

By having this monitoring feature,

load balancers can intelligently balance the load

only among healthy servers

while ignoring the ones that are considered to be dead

or excessively slow.

Now, let's see how load balancers

affect the system's performance.

When it comes to performance,

load balancers may add a little bit of latency

and increase their response time to the user,

but it's generally an acceptable price to pay

for an increased performance in terms of throughput.

Since the load balancer allows us

to theoretically have as many backend servers as we like,

of course, with some reasonable limitations,

the number of requests or tasks

that we can perform per unit of time

is much larger than the throughput we could get

from a single server.

Another important quality attribute

that the load balancer helps us achieve is maintainability.

Since we can easily add or remove servers to the rotation,

we can take down individual servers one-by-one

to prefer maintenance

or upgrade the application version

without any disruption to the client.

And when the maintenance on that server is complete,

we can add it back to the load balancer

and take down the next server.

This way we can have a rolling release,

while still keeping our SLA in terms of availability.

Now, finally, let's talk about

a few different types of load balancers

that we can choose from.

One of the most basic load balancers

can be achieved through DNS.

The Domain Name System

is part of the internet infrastructure

that maps human-friendly URLs, like amazon.com,

netflix.com, or apple.com

to IP addresses that can be used by network routers

to route requests to individual computers on the web.

It's essentially the phone book of the internet.

So when a user or a client application

wants to communicate with our system,

the user sends a DNS query to the DNS server

and the DNS responds with an IP address

that corresponds to our domain name.

Then, the client application can use that IP address

to send a request directly to the server.

However, a single DNS record doesn't have to be mapped

to a single IP address

and can be easily configured

to return a list of IP addresses

corresponding to different servers.

Most DNS servers are implemented in such a way

that they return the list of addresses for each domain

in a different order on each client request

and by convention, most client applications

simply pick the first address in the list

that uses the resolved IP address for a particular domain.

This way, the domain naming system

essentially balances the load on our servers

by simply rotating this list in a round-robin fashion.

Now, although this way of providing

load balancing capability is super simple and cheap,

as it essentially comes for free

by purchasing a domain name,

it has a few drawbacks.

The main drawback is that DNS

doesn't monitor the health of our servers.

In other words, if one of our servers stops responding,

the Domain Name System will not know about it

and will continue referring clients

to that particular server.

This list of IP addresses changes only so often

and is based on the time to live

that was configured for that particular DNS record.

Additionally, this list of addresses

that a particular domain name is mapped to

can be cached in different locations,

such as the client's computer.

That makes the time

between a particular server going down

and the point that the requests

are no longer sent to that server even longer.

Another drawback of DNS-based load balancing

is that the load balancing strategy

is always just as simple as round-robin,

which doesn't take into account

the fact that some of our application instances

may be running on more powerful servers than others,

nor can it detect that one of our servers

may be more overloaded than the others.

The third drawback of the DNS-based load balancing

is the declined application

gets the direct IP addresses of all our servers.

This exposes some implementation details of our system

and more importantly, makes our system less secure.

The reason for that is that there is nothing

that prevents a malicious client application

from just picking one IP address

and send requests only to that particular server

which, of course, would overload it more than others.

To address all those drawbacks,

there are two load balancing solutions

that are a lot more powerful and intelligent.

Those two types of solutions are hardware load balancers

and software load balancers.

The only difference

between those two types of load balancers

is that hardware load balancers run on dedicated devices

designed and optimized specifically for load balancing,

while software load balancers are just programs

that can run on any general-purpose computer

and perform the load balancing function.

In the case of software and hardware load balancers,

in contrast to DNS load balancing,

all the communication between the client

and our group of servers is done through the load balancer.

In other words, the individual IP addresses,

as well as the number of servers

we have behind the load balancer

are not exposed to the users,

which makes our system a lot more secure.

Another feature of hardware and software load balancers

is that they can actively monitor the health of our servers

and send them periodic health checks

to actively detect if one of our servers

became unresponsive.

Finally, both hardware and software load balancers

can balance the load among our servers

a lot more intelligently,

taking to account the different types of hardware

our application instances are running on,

the current load on each server,

the number of open connections, and so on.

The nice thing about software and hardware load balancers

is in addition to balancing requests from external users,

they can also be used inside our system

to create an abstraction between different services.

For example, if we have an online store system,

we can separate at the service

that responds directly to client requests

and serves the front end to the client browsers

from the fulfillment service and the billing service.

Each such service can be deployed independently

as multiple application instances

running on a group of servers.

And those services communicate with each other

through a load balancer.

This way, we can scale each such service

completely independently

and transparently to the other service.

While software and hardware load balancers

are superior to DNS in terms of load balancing, monitoring,

failure recovery and security,

they are usually collocated with the group of servers

they balance the load on.

The reason for that is if we put the load balancer

too far from the actual servers,

we're adding a lot of extra latency

since all the communication,

both to the servers and back to the client,

has to go through the load balancer.

So if we run system in multiple geographical locations,

which are commonly referred to as data centers,

then having only one load balancer

for both groups of servers will sacrifice the performance

for at least one of those locations.

Additionally, load balancers, on their own,

do not solve the DNS resolution problem,

so we would still need some kind of DNS solution

to map human readable domain names to an IP address.

For that, there is a fourth load balancing solution,

which is called Global Server Load Balancer,

or GSLB in short.

A GSLB is somewhat of a hybrid between a DNS service

and the hardware or software load balancer.

A GSLB solution typically can provide a DNS service

just like any other DNS server that we're familiar with.

However, in addition,

it also can make more intelligent routing decisions.

On one hand, the GSLB can figure out the user's location

based on the origin IP inside the incoming request.

On the other hand,

a GSLB service has similar monitoring capabilities

to a typical software or hardware load balancer.

So at any given moment, it knows the location

and state of each server that we register with our GSLB.

In a typical large-scale system deployment,

those servers are load balancers

located in different data centers

in different geographical locations.

So when a user sends a DNS query to the GSLB,

the GSLB may return just the address

of the most nearby load balancer.

From that point on, the user will use that IP address

to communicate directly

with our system in that data center

through a collocated software or hardware load balancer.

The cool part about GSLBs

is that most GSLBs can be configured to route traffic

based on a variety of strategies

and not just by physical location.

Since they're in constant communication

with our data centers,

they can be configured to route users

based on their current traffic

or CPU load on each data center

or based on the best estimated response time

or bandwidth between the user

and that particular data center.

Thanks to this great feature,

we can provide the best performance possible for each user,

regardless of their geographical location.

Additionally, GSLBs play a very important role

in disaster recovery situations.

If there's a natural disaster

or a power outage in one of our data centers,

the users can be easily routed to different locations,

which provides us with higher availability.

Finally, to prevent a load balancer

from being a single point of failure in each region,

we can place multiple load balancers

and register all their addresses

with the GSLB's DNS service or any other DNS service.

So the client applications

can get a list of all our load balancers

and either send a request to the first one in the list

or pick one themselves randomly.

We learned a lot in this lecture,

so let's quickly summarize it.

In this lecture,

we learned about a very important

software architecture building block,

the load balancer.

We learned about four load balancing solutions,

which are DNS load balancing,

hardware load balancing,

software load balancing,

and Global Server Load Balancing.

Later, we talked about the different quality attributes

that the load balancer provides to our system.

And finally, we saw how we can combine

all those different solutions

to architect a large-scale system

that can provide high performance and high availability,

and scale to millions of users

located in different geographical locations.